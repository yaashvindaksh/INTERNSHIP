{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be3fc08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sweetviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20220\\1958157891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msweetviz\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sweetviz'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings ( 'ignore' )\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pd.set_option ( 'display.max_columns' , None )\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression , Ridge , Lasso \n",
    "\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV , KFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder , MinMaxScaler , Normalizer , StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier , GradientBoostingClassifier , StackingClassifier \n",
    "\n",
    "from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score , confusion_matrix , roc_curve , roc_auc_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cebf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.read_csv ( \"glass.data\" , names = [ 'ID' , 'Refractive_Index' , 'Sodium_%' , 'Magnesium_%' , 'Aluminium_%' , \n",
    "                                           'Silicon_%' , 'Potassium_%' , 'Calcium_%' , 'Barium_%' , 'Iron_%' , \n",
    "                                           'Type_Of_Glass' ]  )\n",
    "\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "Description = pd.DataFrame ( DF.describe ( ) ).transpose ( ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaf6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure ( figsize = ( 15 , 10 ) );\n",
    "\n",
    "sns.lineplot ( y = 'Refractive_Index' , x = 'Type_Of_Glass', data = DF , color = '#7E4E60' , marker = '*');\n",
    "\n",
    "plt.xlabel ( \"Type of Glass\" );\n",
    "\n",
    "plt.ylabel ( \"Refractive Index\" );\n",
    "\n",
    "plt.title ( \"Comparing Types of Glass and Refractive Index\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chemicals = DF.groupby ( by = DF.Type_Of_Glass ).mean ( ).reset_index( ).transpose ( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eceb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure ( figsize = ( 10 , 10 ) )\n",
    "\n",
    "Chemicals.iloc [ 3 : , : ].plot ( kind = 'bar' , label = [ 'building_windows_float_processed' , \n",
    "                                                  \n",
    "                                                  'building_windows_non_float_processed' , \n",
    "                                                  \n",
    "                                                  'vehicle_windows_float_processed' , 'containers' , 'tableware' , \n",
    "                                                  \n",
    "                                                  'headlamps' ] );\n",
    "\n",
    "plt.title ( \"The chemical composition in each glass\" )\n",
    "\n",
    "plt.xlabel ( \"Chemical Percentage\" )\n",
    "\n",
    "plt.ylabel ( \"Percentage\" );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure ( figsize = ( 15 , 15) )\n",
    "sns.heatmap ( data = DF.iloc [ : , 2 : ].corr ( ) ,  annot = True , fmt = '.0f' , cmap = 'BuPu' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f79bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.iloc [ : , 2 : ].plot ( kind = 'box' , subplots = True , layout = ( 3 , 3 ) , sharex = False , sharey = False , figsize = ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea1872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers = DF.iloc [ : , 2 : -1 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8cc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Outliers : \n",
    "        \n",
    "    Outliers[Outliers [i] < Outliers [ i ].quantile ( 0.10 )] = Outliers [ i ].mean ( ) \n",
    "\n",
    "    Outliers[Outliers [i] > Outliers [ i ].quantile ( 0.90 )] = Outliers [ i ].mean ( ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Outliers.plot ( kind = 'box' , subplots = True , layout = ( 3 , 3 ) , sharex = False , sharey = False , figsize = ( 15 , 15) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.drop ( columns = [ 'ID' ] , inplace = True )\n",
    "\n",
    "Train , Test = train_test_split ( DF , test_size = 0.15 , random_state = 42 )\n",
    "\n",
    "Train_X = Train.iloc [ : , : - 1 ]\n",
    "\n",
    "Train_Y = Train.iloc [ : ,  -1 ]\n",
    "\n",
    "Test_X = Test.iloc [ : , : - 1 ]\n",
    "\n",
    "Test_Y = Test.iloc [ : ,  -1 ]\n",
    "\n",
    "print ( \"The shapes of the data sets are : \" )\n",
    "\n",
    "print ( \"\\nTrain >> {} , Test >> {}\\n\\nTrain_X >> {} , Train_Y >> {}\\n\\nTest_X >> {} , Test_Y >> {}\".format ( Train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd832b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression ( )\n",
    "\n",
    "LR.fit ( Train_X ,Train_Y )\n",
    "\n",
    "Y_LR = LR.predict ( Test_X )\n",
    "\n",
    "Accuracy_LR = np.round ( accuracy_score ( Test_Y , Y_LR ) * 100 , 2 ) \n",
    "\n",
    "print ( \"The accuracy of the Test Data is : \" , Accuracy_LR )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion_Matrix_LR = confusion_matrix ( Test_Y , Y_LR )\n",
    "\n",
    "sns.heatmap ( Confusion_Matrix_LR , annot = True , fmt = '.0f' , cmap = 'BuPu' )\n",
    "\n",
    "plt.xlabel ( \"Predicted\" )\n",
    "\n",
    "plt.ylabel ( \"Actual\" )\n",
    "\n",
    "plt.title ( \"Confusion Matrix\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753cdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = LR.predict(Train_X)\n",
    "\n",
    "test_predictions = LR.predict(Test_X)\n",
    "\n",
    "train_accuracy = np.round ( accuracy_score ( Train_Y, train_predictions ) * 100 , 2 )\n",
    "\n",
    "test_accuracy = np.round ( accuracy_score ( Test_Y, test_predictions ) * 100 , 2 )\n",
    "\n",
    "print ( \"Train Accuracy >> {}\\n\\nTest Accuracy >> {}\".format ( train_accuracy , test_accuracy ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier ( )\n",
    "\n",
    "Parameters = { 'n_estimators' : [ 50 , 100 , 150 , 200 ],\n",
    "              \n",
    "               'criterion' : [ 'gini' , 'entropy' ],\n",
    "              \n",
    "               'max_depth' : [ 5 , 10 , 15 ] ,\n",
    "             \n",
    "               'min_samples_split' : [ 5 , 10 , 15 ] }\n",
    "\n",
    "GS = GridSearchCV ( estimator = RF , param_grid = Parameters , cv = 5 )\n",
    "\n",
    "GS.fit ( Train_X , Train_Y )\n",
    "\n",
    "Parameters = GS.best_params_ \n",
    "\n",
    "print ( \"The best parameters are : \\n\\n\" , Parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f63c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier ( **Parameters )\n",
    "\n",
    "RF.fit ( Train_X , Train_Y )\n",
    "\n",
    "Y_RF = RF.predict ( Test_X )\n",
    "\n",
    "Accuracy_RF = np.round ( accuracy_score ( Test_Y , Y_RF ) * 100 , 2 )\n",
    "\n",
    "print ( \"The accuracy of the Test Data is : \" , Accuracy_RF )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Confusion_Matrix_RF = confusion_matrix ( Test_Y , Y_RF )\n",
    "\n",
    "Confusion_Matrix_RF = sns.heatmap ( Confusion_Matrix_RF , fmt = '0.0f' , annot = True , cmap = 'RdGy' )\n",
    "\n",
    "Confusion_Matrix_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = RF.predict ( Train_X )\n",
    "\n",
    "test_predictions = RF.predict ( Test_X )\n",
    "\n",
    "train_accuracy = np.round ( accuracy_score ( Train_Y, train_predictions ) * 100 , 2 ) \n",
    "\n",
    "test_accuracy = np.round ( accuracy_score ( Test_Y, test_predictions ) * 100 , 2 ) \n",
    "\n",
    "print ( \"Train Accuracy >> {}\\n\\nTest Accuracy >> {}\".format ( train_accuracy , test_accuracy ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier (  )\n",
    "\n",
    "Parameters = { 'criterion' : [ 'gini' , 'entropy' ],\n",
    "              \n",
    "               'splitter' : [ 'best' , 'random' ],\n",
    "              \n",
    "               'max_depth' : [ None ,  5 , 10 , 15 ] ,\n",
    "             \n",
    "               'max_features' : [ \"auto\", \"sqrt\", \"log2\" ] }\n",
    "\n",
    "GS = GridSearchCV ( estimator = DT , param_grid = Parameters , cv = 5 )\n",
    "\n",
    "GS.fit ( Train_X , Train_Y )\n",
    "\n",
    "Parameters = GS.best_params_\n",
    "\n",
    "print ( \"The best parameters of decision tree are : \\n\\n\" , Parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aad5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier ( **Parameters )\n",
    "\n",
    "DT.fit ( Train_X , Train_Y )\n",
    "\n",
    "Y_DT = DT.predict ( Test_X )\n",
    "\n",
    "Accuracy_DT = np.round ( accuracy_score ( Test_Y , Y_DT ) * 100 , 2 ) \n",
    "\n",
    "print ( \"The accuracy of the test data is : \" , Accuracy_DT )\n",
    "\n",
    "Confusion_Matrix_DT = sns.heatmap ( confusion_matrix ( Test_Y , Y_DT ) , fmt = '0.0f' , annot = True , cmap = 'PuBu' )\n",
    "\n",
    "Confusion_Matrix_DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7522ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_DT_Train = DT.predict ( Train_X )\n",
    "\n",
    "Train_Accuracy = np.round ( accuracy_score ( Train_Y , Y_DT_Train ) * 100 , 2 )\n",
    "\n",
    "\n",
    "if int ( Train_Accuracy - Accuracy_DT ) > 5.0  :\n",
    "    \n",
    "    print ( \"There is overfitting\"  )\n",
    "    \n",
    "else :\n",
    "    \n",
    "    print ( \"There is no overfitting\\n\"  )\n",
    "\n",
    "print ( \"\\nThe Training accuracy is : {} \\n\\nThe Testing accuracy is : {}\".format( Train_Accuracy , Accuracy_DT ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93671ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier ( )\n",
    "\n",
    "Parameters = {  'loss' : [ 'log_loss' ,'deviance', 'exponential' ] ,\n",
    "    \n",
    "                'learning_rate' : [ 0.1 , 0.01 , 0.001 ] ,\n",
    "    \n",
    "                'n_estimators' : [ 50 , 100 , 150  ] }\n",
    "\n",
    "GS = GridSearchCV ( estimator = GB , param_grid = Parameters )\n",
    "\n",
    "GS.fit ( Train_X , Train_Y )\n",
    "\n",
    "Parameters = GS.best_params_ \n",
    "\n",
    "print ( \"The the most optimum parameters are : \\n\\n\" , Parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b65b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = GradientBoostingClassifier ( **Parameters )\n",
    "\n",
    "GB.fit ( Train_X , Train_Y )\n",
    "\n",
    "Y_GB = GB.predict ( Test_X )\n",
    "\n",
    "Accuracy_GB = np.round ( accuracy_score ( Test_Y , Y_GB ) * 100 , 2 )\n",
    "\n",
    "print ( \"Accuracy of gradient boosting is : \" ,  Accuracy_GB )\n",
    "\n",
    "Confusion_Matrix_GB = sns.heatmap ( confusion_matrix ( Test_Y , Y_GB ) , annot = True , fmt = '0.0f' , cmap = 'RdGy_r' )\n",
    "\n",
    "Confusion_Matrix_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865bc9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_GB_Train = GB.predict ( Train_X )\n",
    "\n",
    "Train_Accuracy = np.round ( accuracy_score ( Train_Y , Y_GB_Train ) * 100 , 2 )\n",
    "\n",
    "\n",
    "if int ( Train_Accuracy - Accuracy_GB ) > 5.0  :\n",
    "    \n",
    "    print ( \"There is overfitting\"  )\n",
    "    \n",
    "else :\n",
    "    \n",
    "    print ( \"There is no overfitting\\n\"  )\n",
    "\n",
    "print ( \"\\nThe Training accuracy is : {} \\n\\nThe Testing accuracy is : {}\".format( Train_Accuracy , Accuracy_GB ) )\n",
    "There is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a68d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier ( )\n",
    "\n",
    "Parameters = {\n",
    "    \n",
    "    'n_estimators': [100, 200, 300],\n",
    "    \n",
    "    'learning_rate': [ 0.5 , 0.1, 0.01, 0.001],  \n",
    "    \n",
    "    'max_depth': [3, 5, 7]  \n",
    "    \n",
    "}\n",
    "\n",
    "LE = LabelEncoder ( )\n",
    "\n",
    "Train_Y = LE.fit_transform ( Train_Y )\n",
    "\n",
    "Test_Y = LE.fit_transform ( Test_Y )\n",
    "\n",
    "GS = GridSearchCV ( estimator = XGBClassifier ( ) , param_grid = Parameters )\n",
    "\n",
    "GS.fit ( Train_X , Train_Y )\n",
    "\n",
    "Parameters = GS.best_params_ \n",
    "\n",
    "print ( \"The the most optimum parameters are : \\n\\n\" , Parameters )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier ( **Parameters )\n",
    "\n",
    "XGB.fit ( Train_X , Train_Y )\n",
    "\n",
    "Y_XGB = XGB.predict ( Test_X )\n",
    "\n",
    "Accuracy_XGB = np.round ( accuracy_score ( Test_Y , Y_XGB ) * 100 , 2 )\n",
    "\n",
    "print ( \"Accuracy of extreme gradient boosting is : \" ,  Accuracy_XGB )\n",
    "\n",
    "Confusion_Matrix_XGB = sns.heatmap ( confusion_matrix ( Test_Y , Y_XGB ) , annot = True , fmt = '0.0f' , cmap = 'twilight' )\n",
    "\n",
    "Confusion_Matrix_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddec3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_XGB_Train = XGB.predict ( Train_X )\n",
    "\n",
    "Train_Accuracy = np.round ( accuracy_score ( Train_Y , Y_XGB_Train ) * 100 , 2 )\n",
    "\n",
    "\n",
    "if int ( Train_Accuracy - Accuracy_XGB ) > 5.0  :\n",
    "    \n",
    "    print ( \"There is overfitting\"  )\n",
    "    \n",
    "else :\n",
    "    \n",
    "    print ( \"There is no overfitting\\n\"  )\n",
    "\n",
    "print ( \"\\nThe Training accuracy is : {} \\n\\nThe Testing accuracy is : {}\".format( Train_Accuracy , Accuracy_XGB ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec649337",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracies = [ Accuracy_DT , Accuracy_LR , Accuracy_GB , Accuracy_RF , Accuracy_XGB ]\n",
    "\n",
    "Accuracies_Names = [ 'Accuracy_DT' , 'Accuracy_LR' , 'Accuracy_GB' , 'Accuracy_RF' , 'Accuracy_XGB' ]\n",
    "\n",
    "Performance_Metrics = { 'Accuracies' : Accuracies , 'Values' : Accuracies_Names }\n",
    "\n",
    "Performance_Metrics = pd.DataFrame(Performance_Metrics)\n",
    "\n",
    "Performance_Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29df26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f981df0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e13069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
